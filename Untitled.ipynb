{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9984/3932352197.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9984/3932352197.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mperson_detections\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[0mrects\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperson_detections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Before runnig this file make sure you have Pretrained model and classes folder\n",
    "#you can get all thing via my github link i will mention below\n",
    "#It will depend on CPU performance if your cpu performance is good the video will process fast\n",
    "#i have not good cpu performacnce to that why its processing quite low\n",
    "import cv2\n",
    "import datetime\n",
    "import imutils\n",
    "import numpy as np\n",
    "from centroidtracker import CentroidTracker\n",
    "from itertools import combinations\n",
    "import math\n",
    "#THE model and prototype files are here\n",
    "protopath = \"MobileNetSSD_deploy.prototxt.txt\"\n",
    "modelpath = \"MobileNetSSD_deploy.caffemodel\"\n",
    "detector = cv2.dnn.readNetFromCaffe(prototxt=protopath, caffeModel=modelpath)\n",
    "\n",
    "#mention num of classes here\n",
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "           \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "           \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "           \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "tracker = CentroidTracker(maxDisappeared=40, maxDistance=60)\n",
    "\n",
    "\n",
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "    try:\n",
    "        if len(boxes) == 0:\n",
    "            return []\n",
    "\n",
    "        if boxes.dtype.kind == \"i\":\n",
    "            boxes = boxes.astype(\"float\")\n",
    "\n",
    "        pick = []\n",
    "\n",
    "        x1 = boxes[:, 0]\n",
    "        y1 = boxes[:, 1]\n",
    "        x2 = boxes[:, 2]\n",
    "        y2 = boxes[:, 3]\n",
    "\n",
    "        area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "        idxs = np.argsort(y2)\n",
    "\n",
    "        while len(idxs) > 0:\n",
    "            last = len(idxs) - 1\n",
    "            i = idxs[last]\n",
    "            pick.append(i)\n",
    "\n",
    "            xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "            yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "            xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "            yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "            w = np.maximum(0, xx2 - xx1 + 1)\n",
    "            h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "            overlap = (w * h) / area[idxs[:last]]\n",
    "\n",
    "            idxs = np.delete(idxs, np.concatenate(([last],\n",
    "                                                   np.where(overlap > overlapThresh)[0])))\n",
    "\n",
    "        return boxes[pick].astype(\"int\")\n",
    "    except Exception as e:\n",
    "        print(\"Exception occurred in non_max_suppression : {}\".format(e))\n",
    "#Pass the video link here\n",
    "\n",
    "def main():\n",
    "    cap =cv2.VideoCapture('Social Distance.mp4')\n",
    "\n",
    "    fps_start_time = datetime.datetime.now()\n",
    "    fps = 0\n",
    "    total_frames = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        frame = imutils.resize(frame, width=600)\n",
    "        total_frames = total_frames + 1\n",
    "\n",
    "        (H, W) = frame.shape[:2]\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(frame, 0.007843, (W, H), 127.5)\n",
    "\n",
    "        detector.setInput(blob)\n",
    "        person_detections = detector.forward()\n",
    "        rects = []\n",
    "        for i in np.arange(0, person_detections.shape[2]):\n",
    "            confidence = person_detections[0, 0, i, 2]\n",
    "            if confidence > 0.5:\n",
    "                idx = int(person_detections[0, 0, i, 1])\n",
    "\n",
    "                if CLASSES[idx] != \"person\":\n",
    "                    continue\n",
    "\n",
    "                person_box = person_detections[0, 0, i, 3:7] * np.array([W, H, W, H])\n",
    "                (startX, startY, endX, endY) = person_box.astype(\"int\")\n",
    "                rects.append(person_box)\n",
    "\n",
    "        boundingboxes = np.array(rects)\n",
    "        boundingboxes = boundingboxes.astype(int)\n",
    "        rects = non_max_suppression_fast(boundingboxes, 0.3)\n",
    "        centroid_dict = dict()\n",
    "        objects = tracker.update(rects)\n",
    "        for (objectId, bbox) in objects.items():\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            x1 = int(x1)\n",
    "            y1 = int(y1)\n",
    "            x2 = int(x2)\n",
    "            y2 = int(y2)\n",
    "            cX = int((x1 + x2) / 2.0)\n",
    "            cY = int((y1 + y2) / 2.0)\n",
    "\n",
    "\n",
    "            centroid_dict[objectId] = (cX, cY, x1, y1, x2, y2)\n",
    "\n",
    "            # text = \"ID: {}\".format(objectId)\n",
    "            # cv2.putText(frame, text, (x1, y1-5), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 1)\n",
    "\n",
    "        red_zone_list = []\n",
    "        for (id1, p1), (id2, p2) in combinations(centroid_dict.items(), 2):\n",
    "            dx, dy = p1[0] - p2[0], p1[1] - p2[1]\n",
    "            distance = math.sqrt(dx * dx + dy * dy)\n",
    "            if distance < 75.0: \n",
    "                if id1 not in red_zone_list:\n",
    "                    red_zone_list.append(id1)\n",
    "                if id2 not in red_zone_list:\n",
    "                    red_zone_list.append(id2)\n",
    "\n",
    "        for id, box in centroid_dict.items():\n",
    "            if id in red_zone_list:\n",
    "                cv2.rectangle(frame, (box[2], box[3]), (box[4], box[5]), (0, 0, 255), 2)\n",
    "            else:\n",
    "                cv2.rectangle(frame, (box[2], box[3]), (box[4], box[5]), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "        fps_end_time = datetime.datetime.now()\n",
    "        time_diff = fps_end_time - fps_start_time\n",
    "        if time_diff.seconds == 0:\n",
    "            fps = 0.0\n",
    "        else:\n",
    "            fps = (total_frames / time_diff.seconds)\n",
    "\n",
    "        fps_text = \"FPS: {:.2f}\".format(fps)\n",
    "\n",
    "        cv2.putText(frame, fps_text, (5, 30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 1)\n",
    "\n",
    "        cv2.imshow(\"Social_Distancing\", frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before runnig this file make sure you have Pretrained model and classes folder\n",
    "#you can get all thing via my github link i will mention below\n",
    "#It will depend on CPU performance if your cpu performance is good the video will process fast\n",
    "#i have not good cpu performacnce to that why its processing quite low\n",
    "import cv2\n",
    "import datetime\n",
    "import imutils\n",
    "import numpy as np\n",
    "from centroidtracker import CentroidTracker\n",
    "from itertools import combinations\n",
    "import math\n",
    "#THE model and prototype files are here\n",
    "protopath = \"MobileNetSSD_deploy.prototxt.txt\"\n",
    "modelpath = \"MobileNetSSD_deploy.caffemodel\"\n",
    "detector = cv2.dnn.readNetFromCaffe(prototxt=protopath, caffeModel=modelpath)\n",
    "\n",
    "#mention num of classes here\n",
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "           \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "           \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "           \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "tracker = CentroidTracker(maxDisappeared=40, maxDistance=60)\n",
    "\n",
    "\n",
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "    try:\n",
    "        if len(boxes) == 0:\n",
    "            return []\n",
    "\n",
    "        if boxes.dtype.kind == \"i\":\n",
    "            boxes = boxes.astype(\"float\")\n",
    "\n",
    "        pick = []\n",
    "\n",
    "        x1 = boxes[:, 0]\n",
    "        y1 = boxes[:, 1]\n",
    "        x2 = boxes[:, 2]\n",
    "        y2 = boxes[:, 3]\n",
    "\n",
    "        area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "        idxs = np.argsort(y2)\n",
    "\n",
    "        while len(idxs) > 0:\n",
    "            last = len(idxs) - 1\n",
    "            i = idxs[last]\n",
    "            pick.append(i)\n",
    "\n",
    "            xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "            yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "            xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "            yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "            w = np.maximum(0, xx2 - xx1 + 1)\n",
    "            h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "            overlap = (w * h) / area[idxs[:last]]\n",
    "\n",
    "            idxs = np.delete(idxs, np.concatenate(([last],\n",
    "                                                   np.where(overlap > overlapThresh)[0])))\n",
    "\n",
    "        return boxes[pick].astype(\"int\")\n",
    "    except Exception as e:\n",
    "        print(\"Exception occurred in non_max_suppression : {}\".format(e))\n",
    "#Pass the video link here\n",
    "\n",
    "def main():\n",
    "    cap =cv2.VideoCapture(0)\n",
    "\n",
    "    fps_start_time = datetime.datetime.now()\n",
    "    fps = 0\n",
    "    total_frames = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        frame = imutils.resize(frame, width=600)\n",
    "        total_frames = total_frames + 1\n",
    "\n",
    "        (H, W) = frame.shape[:2]\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(frame, 0.007843, (W, H), 127.5)\n",
    "\n",
    "        detector.setInput(blob)\n",
    "        person_detections = detector.forward()\n",
    "        rects = []\n",
    "        for i in np.arange(0, person_detections.shape[2]):\n",
    "            confidence = person_detections[0, 0, i, 2]\n",
    "            if confidence > 0.5:\n",
    "                idx = int(person_detections[0, 0, i, 1])\n",
    "\n",
    "                if CLASSES[idx] != \"person\":\n",
    "                    continue\n",
    "\n",
    "                person_box = person_detections[0, 0, i, 3:7] * np.array([W, H, W, H])\n",
    "                (startX, startY, endX, endY) = person_box.astype(\"int\")\n",
    "                rects.append(person_box)\n",
    "\n",
    "        boundingboxes = np.array(rects)\n",
    "        boundingboxes = boundingboxes.astype(int)\n",
    "        rects = non_max_suppression_fast(boundingboxes, 0.3)\n",
    "        centroid_dict = dict()\n",
    "        objects = tracker.update(rects)\n",
    "        for (objectId, bbox) in objects.items():\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            x1 = int(x1)\n",
    "            y1 = int(y1)\n",
    "            x2 = int(x2)\n",
    "            y2 = int(y2)\n",
    "            cX = int((x1 + x2) / 2.0)\n",
    "            cY = int((y1 + y2) / 2.0)\n",
    "\n",
    "\n",
    "            centroid_dict[objectId] = (cX, cY, x1, y1, x2, y2)\n",
    "\n",
    "            # text = \"ID: {}\".format(objectId)\n",
    "            # cv2.putText(frame, text, (x1, y1-5), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 1)\n",
    "\n",
    "        red_zone_list = []\n",
    "        for (id1, p1), (id2, p2) in combinations(centroid_dict.items(), 2):\n",
    "            dx, dy = p1[0] - p2[0], p1[1] - p2[1]\n",
    "            distance = math.sqrt(dx * dx + dy * dy)\n",
    "            if distance < 75.0:\n",
    "                if id1 not in red_zone_list:\n",
    "                    red_zone_list.append(id1)\n",
    "                if id2 not in red_zone_list:\n",
    "                    red_zone_list.append(id2)\n",
    "\n",
    "        for id, box in centroid_dict.items():\n",
    "            if id in red_zone_list:\n",
    "                cv2.rectangle(frame, (box[2], box[3]), (box[4], box[5]), (0, 0, 255), 2)\n",
    "            else:\n",
    "                cv2.rectangle(frame, (box[2], box[3]), (box[4], box[5]), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "        fps_end_time = datetime.datetime.now()\n",
    "        time_diff = fps_end_time - fps_start_time\n",
    "        if time_diff.seconds == 0:\n",
    "            fps = 0.0\n",
    "        else:\n",
    "            fps = (total_frames / time_diff.seconds)\n",
    "\n",
    "        fps_text = \"FPS: {:.2f}\".format(fps)\n",
    "\n",
    "        cv2.putText(frame, fps_text, (5, 30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 1)\n",
    "\n",
    "        cv2.imshow(\"Social_Distancing\", frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
